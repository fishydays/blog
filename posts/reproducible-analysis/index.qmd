---
title: "Reproducibility in Data Analysis: A Comparative Perspective on Virtual Environments and Containers"
author: "Elaine Chu"
date: "2025-01-18"
---

Imagine you are a master chef who just developed the best recipe for chicken adobo. You can’t wait to share this recipe with the rest of the world so they can recreate the dish themselves. How would you go about ensuring others can replicate the dish exactly as you did? Would just providing the recipe be enough? Different kitchens may have different cookware available, and ingredients may differ slightly depending on the country. So just providing the recipe itself may not suffice. 

![Fig 1. The moment you found the best chicken adobo recipe](chef.gif){fig-width=10}

This is a similar question that is faced by data scientists after they created a model and want to share the results of their analysis with others. In data analysis, reproducibility is a cornerstone of credible and reliable work. It ensures others can recreate an analysis and verify its results, fostering trust in the insights derived from the data. However, to achieve this, just providing the code of the analysis is insufficient. We often need to ensure that the differences in computer environments are also addressed so that the analysis can run other computers without any issue. We want to not only have the code for analysis to be reproducible, but the entire computational environment to also be reproducible. There are several tools such as `environment.yaml` files, conda lock files, and docker containers that can help us do exactly that. Each of these tools offers a different level of precision and isolation, much like providing varying degrees of guidance to recreate a dish by a chef. Now let’s explore each of them in detail!

### Environment.yaml Files: The recipe and ingredients

One way to reproduce a computational environment is by using an `environment.yaml` file. Computers can create a virtual environment in their system. Virtual environment is an isolated workspace that allows us to manage and run specific packages and programs without affecting the global environment of the computer. An `environment.yaml` file will provide instructions to create a new virtual environment with the specific packages needed to reproduce the analysis listed. 

This is like the chef sharing the recipe along with a list of ingredients to others. It provides essentials on what is needed to recreate the dish, but it also assumes other people can source the ingredients and figure out the appropriate cookware for it. Similarly, although `environment.yaml` files lists the necessary  packages, it does not specify the exact version or provide information on what dependents those packages may have. Every time someone install an environment using the `environment.yaml` file, it needs to run a solver to figure out which version of the package to install and what are the dependent packages it needs. This could introduce variability and inefficiencies. Is there a way we can overcome this? Enter conda lock files…

![Fig 2. What other materials are needed to cook the recipe](whatelse.gif){fig-width=5}

### Conda Lock Files: A Precise shopping list

Conda lock files are similar to `environment.yaml` files where it gives instructions on how to create a new virtual environment. However, it also includes detailed information on the specific versions of the packages and all the dependent packages are needed. This eliminates the need to run a solver every time someone installs the environment using the conda lock file. This ensures the environment is recreated exactly as specified, ensuring consistency and reducing setup time.

This is similar to the chef giving a precise shopping list of ingredients with the specific brands, quantities, and version listed along with cookware requirements. This minimizes variability and ensures others can recreate the dish as exactly as intended. The added precision does, however, make the conda lock files more complex to create and use when compared to an `environment.yaml` file.

Both `environment.yaml` files and conda lock files create virtual environments, however, sometimes just a virtual environment is not enough. Outside of the programming language and packages used in the analysis, there could be other computer specifications like operating systems or hardware configurations that are needed for the analysis to run. How do we go one step further and address these differences? We can use docker containers…

### Docker Containers: A Fully Equipped Kitchen

Instead of just creating a virtual environment, docker creates a containerized environment. Essentially, it splits up the resource in a computer system itself so it can run in complete isolation. Examples of elements it splits on could be storage devices, network resources, and other hardware capacities. The container will include not only the necessary programming language and packages, but also the operating system and system-level dependencies required for the analysis.

Back to the analogy of the chef, this is like providing a fully equipped and pre-stocked kitchen. All the ingredients and tools you need to make the dish are there without needing to assemble or install anything else. This level of completeness ensures the analysis can be reproduced without any issue. However, docker containers require more expertise to set up and manage, they are heavier and more resource intensive. 
![Fig 3. A fully stocked kitchen just for you to make chicken adobo](kitchencontainer.png){fig-width=5}

### Choosing the right tool

The choice between `environment.yaml` files, conda lock files, and Docker containers really depends on the specific requirements of the data analysis project at hand. If it is a project where minor variations in package versions do not matter, then `environment.yaml` files may be ideal. It is simple and easy to create and share. If we want to have a stricter requirement for package version and dependencies, then conda lock files will be our choice. Although slightly more complex than `environment.yaml` files, they are ideal for projects that require precise reproducibility. Finally, if we want a fully self-contained and portable solution for long-term reproducibility for complex projects, docker containers may be the tool we need. They will require more resources and expertise to use, however, they also offer the highest level of reproducibility and isolation.

By understanding the trade-offs between these different tools allows data scientists to choose the right tool for their project’s needs. Whether it is sharing a recipe, a precise shopping list, or a full equipped kitchen, each approach offers a unique pathway to reproducible and reliable analysis.


